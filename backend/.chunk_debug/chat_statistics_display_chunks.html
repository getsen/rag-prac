<!DOCTYPE html><html><head>
<title>Chunks: chat_statistics_display.md</title>
<meta charset='utf-8'><meta name='viewport' content='width=device-width'>
<style>
body{font-family:Arial,sans-serif;background:#f5f5f5;padding:20px;}
.container{max-width:1400px;margin:0 auto;}
.header{background:#2c3e50;color:white;padding:20px;border-radius:5px;margin-bottom:20px;}
.chunk{background:white;margin-bottom:20px;padding:20px;border-left:4px solid #3498db;border-radius:5px;}
.chunk-title{font-weight:bold;font-size:16px;margin-bottom:10px;}
.chunk-meta{font-size:12px;color:#7f8c8d;margin-bottom:10px;}
.tag{display:inline-block;padding:4px 8px;background:#ecf0f1;border-radius:3px;margin-right:5px;font-size:11px;}
.section-path{color:#27ae60;font-size:12px;margin:8px 0;}
.content{background:#f8f9fa;padding:15px;border-radius:3px;font-family:monospace;font-size:12px;max-height:400px;overflow-y:auto;white-space:pre-wrap;}
</style></head><body>
<div class='container'>
<div class='header'><h1>ðŸ“„ chat_statistics_display.md</h1><p>Total Chunks: 15</p></div>
<div class='chunk'>
<div class='chunk-title'>Chunk #1</div>
<div class='chunk-meta'>Lines 1-2</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation</div>
<div class='content'>Section: Chat Statistics Display Implementation

# Chat Statistics Display Implementation</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #2</div>
<div class='chunk-meta'>Lines 3-6</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Overview</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Overview

## Overview

Successfully implemented detailed statistics display in the chat window, showing context used, token counts, source documents, and processing time for each AI response.</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #3</div>
<div class='chunk-meta'>Lines 7-10</div>
<span class='tag'>merged_section
</span>
<span class='tag'>Has Code</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made

## Changes Made

Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Backend Changes

### Backend Changes</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #4</div>
<div class='chunk-meta'>Lines 11-17</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made > Backend Changes > [schemas.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/models/schemas.py)</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Backend Changes &gt; [schemas.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/models/schemas.py)

#### [schemas.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/models/schemas.py)

Added new statistics models:

- **`SourceDocument`**: Metadata for source documents including filename, chunk info, and relevance score
- **`ResponseStatistics`**: Complete statistics model with token...</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #5</div>
<div class='chunk-meta'>Lines 18-35</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made > Backend Changes > [graph_service.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/services/graph_service.py)</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Backend Changes &gt; [graph_service.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/services/graph_service.py)

#### [graph_service.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/services/graph_service.py)

Updated `chat_stream()` method to track and return statistics:

- Track start time for processing duration calculation
- Collect source documents from RAG results with full...</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #6</div>
<div class='chunk-meta'>Lines 36-46</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made > Backend Changes > [chat.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/routers/chat.py)</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Backend Changes &gt; [chat.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/routers/chat.py)

#### [chat.py](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/backend/app/routers/chat.py)

Updated `stream_generator()` to handle statistics events:

- Modified to handle dictionary items from `graph_service.chat_stream()`
- Emit `token` events for streaming text
- Emit `statistics` events with compl...</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #7</div>
<div class='chunk-meta'>Lines 47-48</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made > Frontend Changes</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Frontend Changes

### Frontend Changes</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #8</div>
<div class='chunk-meta'>Lines 49-58</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made > Frontend Changes > [useChat.ts](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/hooks/useChat.ts)</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Frontend Changes &gt; [useChat.ts](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/hooks/useChat.ts)

#### [useChat.ts](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/hooks/useChat.ts)

Added statistics interfaces and handling:

- **`SourceDocument` interface**: Matches backend model
- **`MessageStatistics` interface**: Complete statistics structure
- Updated `Message` interface to ...</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #9</div>
<div class='chunk-meta'>Lines 59-78</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made > Frontend Changes > [MessageStatistics.tsx](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/components/MessageStatistics.tsx)</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Frontend Changes &gt; [MessageStatistics.tsx](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/components/MessageStatistics.tsx)

#### [MessageStatistics.tsx](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/components/MessageStatistics.tsx)

Created new collapsible statistics component:

**Features:**
- Collapsible section (starts collapsed by default)
- Toggle button showing token co...</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #10</div>
<div class='chunk-meta'>Lines 79-88</div>
<span class='tag'>section
</span>
<div class='section-path'>Chat Statistics Display Implementation > Changes Made > Frontend Changes > [MessageBubble.tsx](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/components/MessageBubble.tsx)</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Changes Made &gt; Frontend Changes &gt; [MessageBubble.tsx](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/components/MessageBubble.tsx)

#### [MessageBubble.tsx](file:///Users/mk/Desktop/workspace/ai-stuff/langgraph/ai-app/frontend/src/components/MessageBubble.tsx)

Integrated statistics component:

- Import `MessageStatisticsComponent`
- Render statistics below assistant messages
- Only shown for assistant messages with sta...</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #11</div>
<div class='chunk-meta'>Lines 89-119</div>
<span class='tag'>merged_section
</span>
<span class='tag'>Has Code</span>
<div class='section-path'>Chat Statistics Display Implementation > Features</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Features

## Features

Section: Chat Statistics Display Implementation &gt; Features &gt; Token Counting

### Token Counting

Uses word-based approximation (words Ã— 1.3) for token estimation:
- Fast and efficient
- Good enough for local models
- Can be replaced with `tiktoken` for OpenAI models if needed

Section: Chat Statistics Display Implementation &gt; Features &gt; Source Document Display

### Source Document Display

Shows comprehensive metadata for e...</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #12</div>
<div class='chunk-meta'>Lines 120-128</div>
<span class='tag'>narrative
</span>
<div class='section-path'>Chat Statistics Display Implementation > Usage</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Usage

## Usage

The statistics are automatically displayed for all assistant responses. Users can:</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #13</div>
<div class='chunk-meta'>Lines 120-128</div>
<span class='tag'>steps
</span>
<div class='section-path'>Chat Statistics Display Implementation > Usage</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Usage

## Usage
1. **See summary**: Token count and processing time in collapsed view
2. **Expand details**: Click toggle to see full statistics
3. **View sources**: See which documents were used for RAG responses
4. **Track reasoning**: See how many reasoning steps were used</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #14</div>
<div class='chunk-meta'>Lines 129-158</div>
<span class='tag'>section
</span>
<span class='tag'>Has Code</span>
<div class='section-path'>Chat Statistics Display Implementation > Example Output</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Example Output

## Example Output

When RAG is enabled, users will see:

```
â–¶ 245 tokens â€¢ 1.23s

[Expanded view shows:]
TOKENS
Input: 180
Output: 65
Total: 245

CONTEXT
Documents Used: 3
Reasoning Steps: 0

SOURCE DOCUMENTS
ðŸ“„ x-wp.pdf
Chunk 2 of 12
[Relevance: 0.85]

ðŸ“„ h04556p1-virtualization-and-clustering-of-neeps-wp.pdf
Chunk 5 of 8
[Relevance: 0.78]

PROCESSING TIME
1.23s
```</div>
</div>
<div class='chunk'>
<div class='chunk-title'>Chunk #15</div>
<div class='chunk-meta'>Lines 159-165</div>
<span class='tag'>steps
</span>
<div class='section-path'>Chat Statistics Display Implementation > Benefits</div>
<div class='content'>Section: Chat Statistics Display Implementation &gt; Benefits

## Benefits
1. **Transparency**: Users see exactly what context was used
2. **Performance insights**: Token counts and processing time visible
3. **Source tracking**: Easy to identify which documents contributed
4. **Debugging**: Helps identify when RAG is/isn't working
5. **Cost awareness**: Token counts help estimate API costs (for OpenAI models)</div>
</div>
</div></body></html>